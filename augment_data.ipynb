{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35447e8a-f878-4913-af79-b0e7756ed6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce39d82e-1dc4-40f2-b4e9-aa79bab357c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corners_from_yolo(bboxes, img_w, img_h):\n",
    "    \"\"\"Convert YOLO format [class, x_center, y_center, width, height] to pixel corner format [x1, y1, x2, y2].\"\"\"\n",
    "    corners = []\n",
    "    for bbox in bboxes:\n",
    "        _, x_center, y_center, width, height = bbox\n",
    "        w = width * img_w\n",
    "        h = height * img_h\n",
    "        x1 = (x_center * img_w) - (w / 2)\n",
    "        y1 = (y_center * img_h) - (h / 2)\n",
    "        x2 = x1 + w\n",
    "        y2 = y1 + h\n",
    "        corners.append([x1, y1, x2, y2])\n",
    "    return np.array(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6667097d-8aed-4f0b-b19f-a7447fb0d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yolo_from_corners(corners, class_ids, img_w, img_h):\n",
    "    \"\"\"Convert pixel corner format [x1, y1, x2, y2] to YOLO format.\"\"\"\n",
    "    yolo_boxes = []\n",
    "    for i, corner in enumerate(corners):\n",
    "        x1, y1, x2, y2 = corner\n",
    "        # Ensure x1 < x2 and y1 < y2\n",
    "        x1, x2 = min(x1, x2), max(x1, x2)\n",
    "        y1, y2 = min(y1, y2), max(y1, y2)\n",
    "        \n",
    "        # Clip to image boundaries\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(img_w, x2), min(img_h, y2)\n",
    "\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue\n",
    "\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        x_center = (x1 + width / 2) / img_w\n",
    "        y_center = (y1 + height / 2) / img_h\n",
    "        \n",
    "        yolo_boxes.append([\n",
    "            class_ids[i], \n",
    "            np.clip(x_center, 0, 1), \n",
    "            np.clip(y_center, 0, 1), \n",
    "            np.clip(width / img_w, 0, 1), \n",
    "            np.clip(height / img_h, 0, 1)\n",
    "        ])\n",
    "    return np.array(yolo_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b33fdc14-3690-40d1-b14f-45859e83f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_boxes(corners_4p, angle, cx, cy):\n",
    "    \"\"\"\n",
    "    Rotate the 4 corners of each bounding box and return the new enclosing box.\n",
    "    Args:\n",
    "        corners_4p: (N, 4, 2) array of N boxes, each with 4 (x,y) corners.\n",
    "        angle: rotation angle in degrees.\n",
    "        cx, cy: rotation center.\n",
    "    Returns:\n",
    "        (N, 4) array of new enclosing bounding boxes in [x1, y1, x2, y2] format.\n",
    "    \"\"\"\n",
    "    all_corners = corners_4p.reshape(-1, 2)\n",
    "    all_corners_hom = np.hstack((all_corners, np.ones((all_corners.shape[0], 1))))\n",
    "\n",
    "    M = cv2.getRotationMatrix2D((cx, cy), angle, 1.0)\n",
    "\n",
    "    rotated_all_corners = np.dot(M, all_corners_hom.T).T\n",
    "    rotated_corners_4p = rotated_all_corners.reshape(-1, 4, 2)\n",
    "\n",
    "    x_min = np.min(rotated_corners_4p[:, :, 0], axis=1)\n",
    "    y_min = np.min(rotated_corners_4p[:, :, 1], axis=1)\n",
    "    x_max = np.max(rotated_corners_4p[:, :, 0], axis=1)\n",
    "    y_max = np.max(rotated_corners_4p[:, :, 1], axis=1)\n",
    "\n",
    "    return np.column_stack((x_min, y_min, x_max, y_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fea17700-c76f-4c93-9ebe-b473ef735b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image, bboxes):\n",
    "    h, w = image.shape[:2]\n",
    "    class_ids = bboxes[:, 0].copy()\n",
    "    augmentations = {}\n",
    "    \n",
    "    # 1. Horizontal Flip\n",
    "    img_hf = cv2.flip(image, 1)\n",
    "    bboxes_hf = bboxes.copy()\n",
    "    bboxes_hf[:, 1] = 1 - bboxes_hf[:, 1]\n",
    "    augmentations['hf'] = (img_hf, bboxes_hf)\n",
    "    \n",
    "    # 2. Brightness Adjustment\n",
    "    brightness = random.uniform(0.7, 1.3)\n",
    "    img_bright = cv2.convertScaleAbs(image, alpha=brightness, beta=0)\n",
    "    augmentations['bright'] = (img_bright, bboxes.copy())\n",
    "    \n",
    "    # 3. Rotation\n",
    "    angle = random.uniform(-10, 10)\n",
    "    rot_mat = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n",
    "    img_rot = cv2.warpAffine(image, rot_mat, (w, h), borderMode=cv2.BORDER_REPLICATE)\n",
    "    \n",
    "    pixel_corners_2p = get_corners_from_yolo(bboxes, w, h)\n",
    "    if pixel_corners_2p.size == 0:\n",
    "        return augmentations # Return other augmentations if no boxes\n",
    "\n",
    "    x1 = pixel_corners_2p[:, 0:1]\n",
    "    y1 = pixel_corners_2p[:, 1:2]\n",
    "    x2 = pixel_corners_2p[:, 2:3]\n",
    "    y2 = pixel_corners_2p[:, 3:4]\n",
    "    \n",
    "    corners_4p = np.hstack([x1, y1, x2, y1, x1, y2, x2, y2]).reshape(-1, 4, 2)\n",
    "\n",
    "    rotated_pixel_corners = rotate_boxes(corners_4p, angle, w/2, h/2)\n",
    "    \n",
    "    bboxes_rot = get_yolo_from_corners(rotated_pixel_corners, class_ids, w, h)\n",
    "    if bboxes_rot.size > 0:\n",
    "        augmentations['rot'] = (img_rot, bboxes_rot)\n",
    "\n",
    "    return augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01147295-8bcb-42a7-bf89-c0f735acc697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(base_dir):\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    image_dir = os.path.join(train_dir, 'images')\n",
    "    label_dir = os.path.join(train_dir, 'labels')\n",
    "\n",
    "    if not os.path.exists(image_dir) or not os.path.exists(label_dir):\n",
    "        print(f\"Error: Training directories not found in {train_dir}\")\n",
    "        return\n",
    "\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.jpeg', '.png')) and not f.startswith('aug_')]\n",
    "    print(f'Found {len(image_files)} original images to augment.')\n",
    "\n",
    "    for image_name in tqdm(image_files, desc='Augmenting Images'):\n",
    "        base_name, ext = os.path.splitext(image_name)\n",
    "        label_name = f'{base_name}.txt'\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        label_path = os.path.join(label_dir, label_name)\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            continue\n",
    "            \n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "            \n",
    "        with open(label_path, 'r') as f:\n",
    "            try:\n",
    "                bboxes = np.array([line.strip().split() for line in f.readlines()], dtype=np.float32)\n",
    "            except ValueError:\n",
    "                continue # Skip malformed label files\n",
    "            \n",
    "        if bboxes.size == 0 or bboxes.shape[1] != 5:\n",
    "            continue\n",
    "            \n",
    "        augmented_data = augment_image(image, bboxes)\n",
    "        \n",
    "        for aug_type, (aug_img, aug_bboxes) in augmented_data.items():\n",
    "            if aug_bboxes.size == 0:\n",
    "                continue\n",
    "            aug_img_name = f'aug_{base_name}_{aug_type}{ext}'\n",
    "            aug_label_name = f'aug_{base_name}_{aug_type}.txt'\n",
    "            cv2.imwrite(os.path.join(image_dir, aug_img_name), aug_img)\n",
    "            np.savetxt(os.path.join(label_dir, aug_label_name), aug_bboxes, fmt='%.6f')\n",
    "\n",
    "    print('\\nData augmentation complete!')\n",
    "    print(f'Total images in training set now: {len(os.listdir(image_dir))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae9482e3-4106-4f9c-8013-2142afd56639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8691 original images to augment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Images: 100%|███████████████████████████████████████████████████████████| 8691/8691 [01:28<00:00, 97.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data augmentation complete!\n",
      "Total images in training set now: 34197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    default_path = 'C:/Empty_Parking/PKLot.v2-640.yolov8'\n",
    "    main(default_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2635781-8f53-4e84-8510-5d0e4a41db89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da8856d-899c-475f-8df9-179b42a404c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d425292-a53d-4d40-830d-78dec6adf097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186c7ff-8f49-4903-a677-a50815ac36f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c858409-c536-469f-bff1-d7360a1c382b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd911336-5829-461f-8ee8-13219dfa5f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fb9f63-19ff-4dc9-b8ca-973debf0f7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83defd8-fb84-4f1c-bf84-76082ec90c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc887e4c-bc10-45bf-907c-e383d25dfcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7bd8b3-4907-4c93-baa7-80dfb7bafb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
