{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de027fe8-3060-4768-b643-6947f33e8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14e44c4-3b3b-4ffa-968f-4f2ae1175745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corners_from_yolo(bboxes, img_w, img_h):\n",
    "    \"\"\"Convert YOLO format [class, x_center, y_center, width, height] to pixel corner format [x1, y1, x2, y2].\"\"\"\n",
    "    corners = []\n",
    "    for bbox in bboxes:\n",
    "        _, x_center, y_center, width, height = bbox\n",
    "        w = width * img_w\n",
    "        h = height * img_h\n",
    "        x1 = (x_center * img_w) - (w / 2)\n",
    "        y1 = (y_center * img_h) - (h / 2)\n",
    "        x2 = x1 + w\n",
    "        y2 = y1 + h\n",
    "        corners.append([x1, y1, x2, y2])\n",
    "    return np.array(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35bef62-3237-4898-8910-088983e52491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yolo_from_corners(corners, class_ids, img_w, img_h):\n",
    "    \"\"\"Convert pixel corner format [x1, y1, x2, y2] to YOLO format.\"\"\"\n",
    "    yolo_boxes = []\n",
    "    for i, corner in enumerate(corners):\n",
    "        x1, y1, x2, y2 = corner\n",
    "        x1, x2 = min(x1, x2), max(x1, x2)\n",
    "        y1, y2 = min(y1, y2), max(y1, y2)\n",
    "        \n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(img_w, x2), min(img_h, y2)\n",
    "\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue\n",
    "\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        x_center = (x1 + width / 2) / img_w\n",
    "        y_center = (y1 + height / 2) / img_h\n",
    "        \n",
    "        yolo_boxes.append([\n",
    "            class_ids[i], \n",
    "            np.clip(x_center, 0, 1), \n",
    "            np.clip(y_center, 0, 1), \n",
    "            np.clip(width / img_w, 0, 1), \n",
    "            np.clip(height / img_h, 0, 1)\n",
    "        ])\n",
    "    return np.array(yolo_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fdb06c5-ae02-4faa-a128-87c98811adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_boxes(corners_4p, angle, cx, cy):\n",
    "    \"\"\"\n",
    "    Rotate the 4 corners of each bounding box and return the new enclosing box.\n",
    "    \"\"\"\n",
    "    all_corners = corners_4p.reshape(-1, 2)\n",
    "    all_corners_hom = np.hstack((all_corners, np.ones((all_corners.shape[0], 1))))\n",
    "\n",
    "    M = cv2.getRotationMatrix2D((cx, cy), angle, 1.0)\n",
    "\n",
    "    rotated_all_corners = np.dot(M, all_corners_hom.T).T\n",
    "    rotated_corners_4p = rotated_all_corners.reshape(-1, 4, 2)\n",
    "\n",
    "    x_min = np.min(rotated_corners_4p[:, :, 0], axis=1)\n",
    "    y_min = np.min(rotated_corners_4p[:, :, 1], axis=1)\n",
    "    x_max = np.max(rotated_corners_4p[:, :, 0], axis=1)\n",
    "    y_max = np.max(rotated_corners_4p[:, :, 1], axis=1)\n",
    "\n",
    "    return np.column_stack((x_min, y_min, x_max, y_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c89a718-0a8a-4b08-bb0d-f53312c79c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image, bboxes):\n",
    "    h, w = image.shape[:2]\n",
    "    class_ids = bboxes[:, 0].copy()\n",
    "    augmentations = {}\n",
    "    \n",
    "    # 1. Vertical Flip\n",
    "    img_vf = cv2.flip(image, 0)\n",
    "    bboxes_vf = bboxes.copy()\n",
    "    bboxes_vf[:, 2] = 1 - bboxes_vf[:, 2] # Flip y-coordinate\n",
    "    augmentations['vf'] = (img_vf, bboxes_vf)\n",
    "\n",
    "    # 2. Brightness Adjustment\n",
    "    brightness = random.uniform(0.6, 1.4)\n",
    "    img_bright = cv2.convertScaleAbs(image, alpha=brightness, beta=0)\n",
    "    augmentations['bright'] = (img_bright, bboxes.copy())\n",
    "    \n",
    "    # 3. Rotation\n",
    "    angle = random.uniform(-15, 15)\n",
    "    rot_mat = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n",
    "    img_rot = cv2.warpAffine(image, rot_mat, (w, h), borderMode=cv2.BORDER_REPLICATE)\n",
    "    \n",
    "    pixel_corners_2p = get_corners_from_yolo(bboxes, w, h)\n",
    "    if pixel_corners_2p.size == 0:\n",
    "        return augmentations\n",
    "\n",
    "    x1 = pixel_corners_2p[:, 0:1]\n",
    "    y1 = pixel_corners_2p[:, 1:2]\n",
    "    x2 = pixel_corners_2p[:, 2:3]\n",
    "    y2 = pixel_corners_2p[:, 3:4]\n",
    "    \n",
    "    corners_4p = np.hstack([x1, y1, x2, y1, x1, y2, x2, y2]).reshape(-1, 4, 2)\n",
    "\n",
    "    rotated_pixel_corners = rotate_boxes(corners_4p, angle, w/2, h/2)\n",
    "    \n",
    "    bboxes_rot = get_yolo_from_corners(rotated_pixel_corners, class_ids, w, h)\n",
    "    if bboxes_rot.size > 0:\n",
    "        augmentations['rot'] = (img_rot, bboxes_rot)\n",
    "\n",
    "    return augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d19ddf79-b453-414f-8a4f-987d55c390be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    source_image_dir = r\"C:\\Empty_Parking\\bounding_box\\P_test\"\n",
    "    source_label_dir = r\"C:\\Empty_Parking\\bounding_box\\P_test_labels\"\n",
    "    \n",
    "    dest_image_dir = r\"C:\\Empty_Parking\\PKLot.v2-640.yolov8\\train\\images\"\n",
    "    dest_label_dir = r\"C:\\Empty_Parking\\PKLot.v2-640.yolov8\\train\\labels\"\n",
    "\n",
    "    os.makedirs(dest_image_dir, exist_ok=True)\n",
    "    os.makedirs(dest_label_dir, exist_ok=True)\n",
    "\n",
    "    image_files = [f for f in os.listdir(source_image_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    print(f'Found {len(image_files)} original images to augment and add to the training set.')\n",
    "\n",
    "    for image_name in tqdm(image_files, desc='Augmenting Images'):\n",
    "        base_name, ext = os.path.splitext(image_name)\n",
    "        label_name = f'{base_name}.txt'\n",
    "        image_path = os.path.join(source_image_dir, image_name)\n",
    "        label_path = os.path.join(source_label_dir, label_name)\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            continue\n",
    "            \n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "            \n",
    "        with open(label_path, 'r') as f:\n",
    "            try:\n",
    "                bboxes = np.array([line.strip().split() for line in f.readlines()], dtype=np.float32)\n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "            \n",
    "        if bboxes.ndim == 1: # Handle single line label files\n",
    "            bboxes = np.array([bboxes])\n",
    "\n",
    "        if bboxes.size == 0 or bboxes.shape[1] != 5:\n",
    "            continue\n",
    "            \n",
    "        augmented_data = augment_image(image, bboxes)\n",
    "        \n",
    "        for aug_type, (aug_img, aug_bboxes) in augmented_data.items():\n",
    "            if aug_bboxes.size == 0:\n",
    "                continue\n",
    "            \n",
    "            # Save to the destination training folder\n",
    "            new_base_name = f'{base_name}_{aug_type}'\n",
    "            aug_img_name = f'{new_base_name}{ext}'\n",
    "            aug_label_name = f'{new_base_name}.txt'\n",
    "            \n",
    "            cv2.imwrite(os.path.join(dest_image_dir, aug_img_name), aug_img)\n",
    "            np.savetxt(os.path.join(dest_label_dir, aug_label_name), aug_bboxes, fmt='%.6f')\n",
    "\n",
    "    print('\\nData augmentation and integration complete!')\n",
    "    print(f'Total images in training set now: {len(os.listdir(dest_image_dir))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0affa54-1ce1-4c94-9d58-3f1c1d75d652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 439 original images to augment and add to the training set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Images: 100%|█████████████████████████████████████████████████████████████| 439/439 [00:04<00:00, 96.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data augmentation and integration complete!\n",
      "Total images in training set now: 34988\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235fd75f-07ee-47c2-a9a9-5a81c5e0e2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38861e53-5ef3-4947-9567-1ba958427583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de48e980-ae8e-44b1-b33c-06bacdbe8a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7236549-0863-41c6-989f-570eeecbfe14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2452ab7a-239c-482e-a698-3460f9ae9b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49971052-aac0-4f8b-955b-6a8e67029136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3396994-fa5b-477c-b818-671ace07f8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4848744b-1cdb-49a3-b461-bb28cd24e25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6042b3-84a6-46e1-b635-40b22decebf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed2348b-e6ee-420c-ae7e-3ce30fd6a81a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77d3ce5-d8ec-45cb-a822-5c3a2c62adf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b7038-918f-4045-917d-6a635c00d8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
